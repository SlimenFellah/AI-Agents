# ğŸ—ºï¸ AI Itinerary Recommendation App 

An AI-powered travel itinerary recommendation system for Algeria ğŸ‡©ğŸ‡¿ using local Large Language Models (LLMs) with **Ollama**, **FastAPI**, **SQLite**, and **CrewAI**.

---

## ğŸ“Œ Features

- ğŸ§  **Local LLMs**: Uses **Ollama** models like `llama2`, `mistral`, etc. â€” no OpenAI key required.
- ğŸ¤– **CrewAI Agents**: Modular agents plan itineraries, select cities, and recommend top destinations.
- ğŸ§³ **Tourism-Focused**: Ideal for exploring Algerian cities with curated highlights.
- âš¡ **FastAPI Backend**: Lightweight API for integration with frontend apps or tools.
- ğŸ—„ï¸ **SQLite Database**: Stores Algerian cities and popular places.

---

## ğŸ“ Project Structure

.
â”œâ”€â”€ main.py # FastAPI app entry point
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ readme.md
â”œâ”€â”€ schema.sql # SQL schema for seeding DB
â”‚
â”œâ”€â”€ api/
â”‚ â””â”€â”€ routes.py # API route handlers
â”‚
â”œâ”€â”€ db/
â”‚ â”œâ”€â”€ database.py # SQLite DB connection
â”‚ â””â”€â”€ seed.py # Seeds cities and places
â”‚
â”œâ”€â”€ agents/
â”‚ â”œâ”€â”€ city_planner.py # CrewAI agent for city selection
â”‚ â””â”€â”€ destination_guide.py # Agent for recommending highlights
â”‚
â””â”€â”€ mycrew/
â””â”€â”€ crew.py # Crew setup with tasks and agents


## ğŸš€ Getting Started

### 1. Install Requirements

```bash
pip install -r requirements.txt
Make sure Ollama is installed and running locally.
```
2. Start Ollama and Pull a Model
```bash
ollama pull llama2
```

3. Run the FastAPI App
```bash
uvicorn main:app --reload
App will be running at http://127.0.0.1:8000
```
## ğŸ”¥ API Endpoint
POST /generate-itinerary
Description: Generates an itinerary with cities and top places in Algeria using LLM agents.

Request:
```bash
{
  "goal": "I want to visit Algeria",
  "preferences": "I like history, architecture, and coastal cities"
}
Response:
{
  "itinerary": {
    "cities": [...],
    "highlights": {
      "Oran": ["Place 1", "Place 2", "Place 3"],
      ...
    }
  }
}
```

## ğŸ§  Local LLM Setup with CrewAI
We use crewAI's built-in LLM support for Ollama:
from crewai import LLM

llm = LLM(
    model="ollama/llama2",
    base_url="http://localhost:11434",
    temperature=0.5
)
Agents and tasks are defined in agents/ and mycrew/crew.py.

## ğŸ—ï¸ Future Improvements
 Add frontend UI (React/Vue)

 More detailed filtering (budget, travel days)

 Add multilingual support (Arabic, French)

 User profiles & itinerary storage

## ğŸ§‘â€ğŸ’» Author
Slimene Fellah
Powered by open-source LLMs & curiosity 
